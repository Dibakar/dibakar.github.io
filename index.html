<html>
<head>
<style>
body {
  font-size: 80%;
  font-family:verdana;
}

h1 {
  font-size: 2.5em;
}

h2 {
  font-size: 1.875em;
}

p {
  font-size: 1em;
}
</style>
</head>
   <head>
      <title>Dibakar Gope's Webpage</title>
   </head>

<body>

   <table border="0" width = "100%" cellpadding="3">
      <tr>
         <font size="4">Dibakar Gope</font><br>
         <br>
         Principal Engineer, Technical Lead<br>
         Machine Learning & AI<br>
         Arm Inc., USA<br>
         <br>
         <!--<a href="https://github.com/Dibakar/">GitHub</a><br>-->
         <a href="https://scholar.google.com/citations?user=cMpWUecAAAAJ&hl=en&oi=ao">Google Scholar</a><br>
         <a href="https://www.linkedin.com/in/dibakar-gope-89060119">Linkedin</a><br>
         <!--<a href="https://dblp.org/pers/hd/g/Gope:Dibakar">DBLP</a><br>-->
         <!--<br>-->
      </tr>
   </table>

<hr noshade="noshade">
<h3>
    <b>About Me</b>
</h3>
<p><!--I am a Senior Research Engineer in the Machine Learning research group at Arm Research in Austin, TX. I have been working on improving the energy efficiency of executing computer vision (CV) and natural language processing (NLP) applications on highly constrained platforms, such as microcontrollers, and personal mobile devices, etc. In that context, I have developed novel compact model architectures, ternary quantization, and low-rank matrix factorization techniques. Besides, I contribute to the design of a next-gen neural hardware accelerator and work on developing new instruction definitions and kernel optimizations for high throughput matrix multiplication.<br>-->
I am a Principal Engineer and Technical Lead in the Machine Learning group at Arm Inc. I have been working on model optimization, algorithm research, and runtime optimization for Generative AI networks such as large language models (LLMs), text-to-image generation diffusion models, and vision transformer networks for on-device, hardware-aware deployment. I have worked on developing resource-efficient computer vision (CV) and natural language processing (NLP/NLU)
models, neural network compression, and neural architecture search techniques for already constrained CV and NLP networks executing on highly constrained platforms, such as microcontrollers, and personal mobile devices, etc. In that context, I have developed novel compact model architectures, sub-byte quantization, low-rank matrix factorization, dynamic execution, and pruning techniques. Besides, I contribute to the design of a next-generation neural hardware accelerator and work on developing new instruction definitions and kernel optimizations for high-throughput matrix multiplication. My research work has resulted in multiple high-impact publications in top-tier machine learning conferences and workshops (CVPR, ICCV, MLSys, NeurIPS). My recent work on generative AI algorithms, runtime optimizations, and associated software development helps to demonstrate the full potential of Arm CPUs and other IPs for LLMs and text-to-image generation models.
<br>

<br>   
Before joining Arm in July 2017, I received a Ph.D. in Electrical Engineering specializing in Machine Learning, Computer Architecture, and AI-Assisted Systems Design from the University of Wisconsin-Madison in 2017. <!--I was advised by <a href="http://www.engr.wisc.edu/ece/faculty/lipasti_mikko.html">Prof. Mikko Lipasti</a>.--!>
During the course of my Ph.D., I conducted original research in designing highly accurate machine learning-guided neural branch prediction for CPU microarchitecture, improving the execution efficiency of PHP scripting language through hardware accelerators and compiler optimizations, and developing efficient memory consistency models for modern processor architecture. My research work has resulted in multiple high-impact publications in top-tier conferences.<!--<br>--><!--computer architecture conferences (ISCA, MICRO, HPCA, PACT).<br>-->
<!--<br>

-->   
I received my Master's Degree (M.S.) in Computer Engineering from Texas A&M University<!-- in 2011-->. During the course of my Master's degree, I conducted original research in design for testing algorithms, and dynamic CMOS circuits.<!--, designed and implemented a
path delay test generator maximizing crosstalk-induced slowdown in modern digital circuits, and performed a detailed evaluation of a circuit and layout fabric based on dynamic circuits.--> This research work resulted in publications in top-tier conferences.<!--<br><br>--><!--circuit/VLSI design conferences (ICCD, MWSCAS).<br><br>-->

I received my Bachelor's Degree (B.E.) in Electrical and Electronics Engineering from the Birla Institute of Technology & Science (Pilani), India<!--, in 2008-->.<br><!--<br>--></p>
<hr noshade="noshade">
<h3>
    <b>Research Interests</b>
</h3>
<p>
<!--Machine Learning, Computer Architecture, Computer Vision, Natural Language Understanding, Natural Language Processing, AI-Optimized Processor and System Design, Processor Microarchitecture -->
Generative AI, Machine learning for constrained systems, theory and design of deep neural networks for CV and NLP/NLU applications, neural network compression techniques, neural architecture search, Computer Vision, Natural Language Understanding, neural network kernel optimizations,
AI-optimized processor and system architecture, computer architecture
<!--Processor Microarchitecture, Hardware Acceleration-->
<!--systems design, performance modeling, profiling, and analysis, HW/SW co-design-->
<br><!--<br>--></p>


<hr noshade="noshade">
<h3>
    <b>Eduction</b>
</h3>

<ul>
    <p><li>
    Ph.D., Electrical Engineering, <font color="maroon">University of Wisconsin-Madison</font>, 2017<br>   
    <!--Ph.D., Electrical Engineering (Specialization: Computer Architecture), <font color="maroon">University of Wisconsin-Madison</font>, 2017<br>--!>
    <!--Dissertation: Architectural Support for Scripting Languages<br>--!>
    <!--Advisor: Professor Mikko H. Lipasti<br>--!>
    Minor: Computer Sciences<br>
    </li></p>

    <p><li>
    M.S., Computer Engineering, <font color="maroon"> Texas A&M University, College Station</font>, 2011<br>
    <!--Advisor: Professor Duncan M. (Hank) Walker--!>
    </li></p>
   
    <p><li>
    B.E. (Hons.), Electrical and Electronics Engineering, <font color="maroon"> Birla Institute of Technology & Science, Pilani, India</font>, 2008<br>
    </li></p>
</ul>

<hr noshade="noshade">
<h3>
    <b>Industrial Experience</b>
</h3>

<ul>
    <p><li>
    Principal Engineer, Machine Learning & AI, <font color="maroon">Arm</font>, Apr. 2024 - Present<br>       
    Staff Research Engineer, Machine Learning & AI, <font color="maroon">Arm Research</font>, Apr. 2021 - Mar. 2024<br>
    Senior Research Engineer, Machine Learning & AI, <font color="maroon">Arm Research</font>, Jul. 2017 - Mar. 2021<br>
    </li></p>

    <p><li>
    Co-Op Engineer, <font color="maroon">AMD Research</font>, Jun. 2015 - Dec. 2015<br>
    </li></p>

    <p><li>
    Co-Op Engineer, <font color="maroon">AMD</font>, May. 2010 - Aug. 2010<br>
    </li></p>
   
    <p><li>
    Design Engineer, <font color="maroon">Freescale Semiconductor</font>, Jul. 2008 - Jul. 2009<br>
    </li></p>
   
    <p><li>
    Project Intern, <font color="maroon">Texas Instruments</font>, Jan. 2008 - Jun. 2008<br>
    </li></p>
   
</ul>
<hr noshade="noshade">
<h3>
    <b>Publications / Patents</b>
</h3>

<ol>
    <li>
    <font color="maroon">Data-Free Group-Wise Fully Quantized Winograd Convolution via Learnable Scales (for Text-to-Image Diffusion Models)</font> [<a href="https://arxiv.org/abs/2412.19867">Paper</a>]
    <br/>Shuokai Pan, Gerti Tuzi, Sudarshan Sreeram, and <span style="font-weight:bold"><u>Dibakar Gope</u></span>
    <br/><span style="font-style:italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition</span> (<b>CVPR</b>), Jun. 2025.
    </li>
    <br />
      
    <li>
    <font color="maroon">Highly Optimized Kernels and Fine-Grained Codebooks for LLM Inference on Arm CPUs</font> [<a href="https://arxiv.org/abs/2501.00032">Paper</a>]
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, David Mansell, Danny Loh, and Ian Bratt
    <br/>ArXiv, 2024.
    </li>
    <br />
       
    <li>
    <font color="maroon">Methods and Processing Elements for Compressing and Decompressing Neural Network Weights</font>
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, David Mansell, Danny Loh, and Ian Bratt
    <br/>US Patent Application, 2024.
    </li>
    <br />
   
    <li>
    <font color="maroon">Quantized Winograd Convolution</font>
    <br/>Shuokai Pan, Gerti Tuzi, and <span style="font-weight:bold"><u>Dibakar Gope</u></span>
    <br/>US Patent Application, 2024.
    </li>
    <br />
       
    <li>
    <font color="maroon">Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers</font> [<a href="https://arxiv.org/abs/2308.10814">Paper</a>]
    <br/>Natalia Frumkin, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Diana Marculescu
    <br/><span style="font-style:italic">International Conference on Computer Vision</span> (<b>ICCV</b>), Oct. 2023.
    </li>
    <br />
      
    <li>
    <font color="maroon">System, Devices and/or Processes for Executing A Neural Network Architecture Search</font>
    <br/>Gerti Tuzi, and <span style="font-weight:bold"><u>Dibakar Gope</u></span>
    <br/>US Patent Application, 2023.
    </li>
    <br />
       
    <li>
    <font color="maroon">PerfSAGE: Generalized Inference Performance Predictor for Arbitrary Deep Learning Models on Edge Devices</font> [<a href="https://arxiv.org/abs/2301.10999">Paper</a>]
    <br/>Yuji Chai, Devashree Tripathy, Chuteng Zhou, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Igor Fedorov, Ramon Matas, David Brooks, Gu-Yeon Wei, Paul Whatmough
    <br/>ArXiv, 2023.
    </li>
    <br />

    <li>
    <font color="maroon">A Neural Processing Unit for Attention-Based Inference</font>
    <br/>Shounak Datta, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Jesse Beu, and Mark O’Connor
    <br/>US Patent Application, 2022.
    </li>
    <br />

    <li>
    <font color="maroon">Restructurable Activation Networks</font> [<a href="https://arxiv.org/abs/2208.08562">Paper</a>]
    <br/>Kartikeya Bhardwaj, James Ward, Caleb Tung*, <span style="font-weight:bold"><u>Dibakar Gope*</u></span>, Lingchuan Meng, Igor Fedorov, Alex Chalfin, Paul Whatmough, Danny Loh (* Equal Contribution)
    <br/>ArXiv, 2022.
    </li>
    <br />

    <li>
    <font color="maroon">Collapsible Linear Blocks for Super-Efficient Super Resolution</font> [<a href="https://arxiv.org/abs/2103.09404">Paper</a>]
    <br/>Kartikeya Bhardwaj, Milos Milosavljevic, Liam O'Neil, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Ramon Matas, Alex Chalfin, Naveen Suda, Lingchuan Meng, Danny Loh
    <br/><span style="font-style:italic">Fifth Conference on Machine Learning and Systems</span> (<b>MLSys</b>), Aug. 2022.
    </li>
    <br />

    <li>
    <font color="maroon">Super-Efficient Super Resolution for Fast Adversarial Defense at the Edge</font> [<a href="https://arxiv.org/abs/2112.14340">Paper</a>]
    <br/>Kartikeya Bhardwaj, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, James Ward, Paul N. Whatmough, Danny Loh
    <br/><span style="font-style:italic">Special Initiative on Autonomous Systems Design (ASD)</span> in conjunction with Design, Automation & Test in Europe (<b>DATE</b>), Mar. 2022.
    </li>
    <br />
   
    <li>
    <font color="maroon">System and Method for Accelerating Neural Networks</font>
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Jesse Beu, and Milos Milosavljevic
    <br/>US Patent Application, 2021.
    </li>
    <br />

    <!--<li>
    <font color="maroon">Building Tightly-Coupled Accelerators Securely from the Ground Up</font> [<a href="">Paper</a>]
    <br/>David Schlais, Mikko Lipasti, <span style="font-weight:bold"><u>Dibakar Gope</u></span>
    <br/>Under Review, 2021
    </li>
    <br />--!>
   
    <li>
    <font color="maroon">MicroNets: Neural Network Architectures for Deploying TinyML Applications on Commodity Microcontrollers</font> [<a href="https://arxiv.org/abs/2010.11267">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Colby Banbury, Chuteng Zhou, Igor Fedorov, Ramon Matas Navarro, Urmish Thakker, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Vijay Janapa Reddi, Matthew Mattina, Paul N. Whatmough
    <br/><span style="font-style:italic">Fourth Conference on Machine Learning and Systems</span> (<b>MLSys</b>), Apr. 2021.
    </li>
    <br />
   
    <li>
    <font color="maroon">System, Devices and/or Processes for Adapting Neural Network Processing Devices</font>
    <br/>Urmish Thakker, Jesse Beu, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Mark O’Connor
    <br/>US Patent Application, 2021.
    </li>
    <br />

    <li>
    <font color="maroon">Compressing RNNs to Kilobyte budget for IoT devices using Kronecker Products</font> [<a href="https://arxiv.org/abs/1906.02876">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Urmish Thakker, Jesse Beu, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Chu Zhou, Igor Fedorov, Ganesh Dasika, and Matthew Mattina
    <br/><span style="font-style:italic">ACM Journal on Emerging Technologies in Computing Systems</span>, 2021.
    </li>
    <br />
      
    <li>
    <font color="maroon">Rank and Run-time aware compression of NLP Applications</font> [<a href="https://arxiv.org/abs/2010.03193">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Urmish Thakker, Jesse Beu, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Ganesh Dasika, Matthew Mattina
    <br/><span style="font-style:italic"> First Workshop on Simple and Efficient Natural Language Processing </span> in conjunction with Empirical Methods in Natural Language Processing (<b>EMNLP</b>), Nov. 2020.
    </li>
    <br />

   
    <li>
    <font color="maroon">Ternary MobileNets via Per-Layer Hybrid Filter Banks</font> [<a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w40/Gope_Ternary_MobileNets_via_Per-Layer_Hybrid_Filter_Banks_CVPRW_2020_paper.pdf">Paper</a>] [<a href="http://openaccess.thecvf.com/content_CVPRW_2020/supplemental/Gope_Ternary_MobileNets_via_CVPRW_2020_supplemental.pdf">Supplemental</a>][<a href="https://arxiv.org/abs/1911.01028">arXiv</a>] <!--[<a href="">Slides</a>] -->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Jesse Beu, Urmish Thakker, and Matthew Mattina
    <br/><span style="font-style:italic">Joint Workshop on Efficient Deep Learning in Computer Vision</span> in conjunction with (<b>CVPR 2020</b>), Jun. 2020.
    </li>
    <br />
      
    <li>
    <font color="maroon">Understanding the Impact of Dynamic Channel Pruning on Conditionally Parameterized Convolutions</font> [<a href="https://dl.acm.org/doi/10.1145/3417313.3429381">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Ravi Raju*, <span style="font-weight:bold"><u>Dibakar Gope*</u></span>, Urmish Thakker, and Jesse Beu (* Equal Contribution)
    <br/><span style="font-style:italic"> 2nd International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things (AIChallengeIoT) </span> in conjunction with ACM (<b>SenSys</b>), Nov. 2020.
    </li>
    <br />    

    <li>
    <font color="maroon">Pushing the Envelope of Dynamic Spatial Gating technologies</font> [<a href="https://dl.acm.org/doi/10.1145/3417313.3429380">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Xueqin Huang, Urmish Thakker, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Jesse Beu
    <br/><span style="font-style:italic"> 2nd International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things (AIChallengeIoT) </span> in conjunction with ACM (<b>SenSys</b>), Nov. 2020.   
    </li>
    <br />
    
    <li>
    <font color="maroon">High Throughput Matrix-Matrix Multiplication between Asymmetric Bit-Width Operands</font> [<a href="https://arxiv.org/abs/2008.00638">arXiv</a>] <!--[<a href="">Slides</a>] -->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Jesse Beu, and Matthew Mattina.
    <br/>ArXiv, 2020.
    </li>
    <br />
      
    <li>
    <font color="maroon">Aggressive Compression of MobileNets Using Hybrid Ternary Layers</font> [<a href="https://tinymlsummit.org/abstracts/Gope_Dibakar_poster_abstract.pdf">Paper</a>] [<a href="https://github.com/Dibakar/dibakar.github.io/blob/master/Posters/tinyML%20Summit%202020%20Poster.pdf">Poster</a>]
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Jesse Beu, Urmish Thakker, and Matthew Mattina
    <br/>tinyML Summit 2020, Feb. 2020.
    </li>
    <br />

    <li>
    <font color="maroon">Mixed-Element-Size Instruction</font>
    <br/>Jesse Beu, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, and David Mansell
    <br/>US Patent Application, 2020.
    </li>
    <br />

    <li>
    <font color="maroon">Mixed-Precision Computation Unit</font>
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Jesse Beu, Paul Whatmough, and Matthew Mattina
    <br/>US Patent Application, 2020.
    </li>
    <br />

    <li>
    <font color="maroon">Hybrid Filter Banks for Artificial Neural Networks</font>
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Jesse Beu, Paul Whatmough, and Matthew Mattina
    <br/>US Patent Application, 2020.
    </li>
    <br />
       
    <li>
    <font color="maroon">Ternary Hybrid Neural-Tree Networks for Highly Constrained IoT Applications (Wake Word Detection)</font> [<a href="https://arxiv.org/abs/1903.01531">Paper</a>] [<a href="https://github.com/Dibakar/dibakar.github.io/blob/master/Posters/SysML%202019%20Poster.pdf">Poster</a>]
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Ganesh Dasika, and Matthew Mattina
    <br/><span style="font-style:italic">Second Conference on Machine Learning and Systems</span> (<b>MLSys</b>), Mar. 2019.
    </li>
    <br /> 
   
    <li>
    <font color="maroon">Pushing the Limits of RNN Compression</font> [<a href="https://arxiv.org/abs/1910.02558">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Urmish Thakker, Igor Fedorov, Jesse Beu, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Chu Zhou, Ganesh Dasika, and Matthew Mattina
    <br/><span style="font-style:italic">5th Workshop on Energy Efficient Machine Learning and Cognitive Computing</span>, <span style="font-style:italic">Co-located with the 33rd Conference on Neural Information Processing Systems</span> (<b>NeurIPS</b>), Dec. 2019.
    </li>
    <br />
   
   
    <li>
    <font color="maroon">Run-Time Efficient RNN Compression for Inference on Edge Devices</font> [<a href="https://arxiv.org/abs/1906.04886">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Urmish Thakker, Jesse Beu, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Ganesh Dasika, and Matthew Mattina
    <br/><span style="font-style:italic">4th Workshop on Energy Efficient Machine Learning and Cognitive Computing for Embedded Applications</span>, <span style="font-style:italic">Co-located with the 46th Int. Symp on Computer Architecture</span> (<b>ISCA</b>), Jun. 2019.
    </li>
    <br />
   
    <li>
    <font color="maroon">RNN Compression using Hybrid Matrix Decomposition</font> <!--[<a href="">PDF</a>] --> <!--[<a href="">Slides</a>] -->
    <br/>Urmish Thakker, Ganesh Dasika, Jesse Beu, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Matthew Mattina
    <br/><span style="font-style:italic">tinyML Summit</span>, Mar. 2019.
    </li>
    <br />

    <li>
    <font color="maroon">Scoped Persistence Barriers for Non-Volatile Memories</font>
    <br/> Arkaprava Basu, Mitesh Meswani, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Sooraj Puthoor
    <br/>US Patent, 2019.
    </li>
    <br />
       
    <li>
    <font color="maroon">A Case for Scoped Persist Barriers in GPUs</font> [<a href="https://www.csa.iisc.ac.in/~arkapravab/papers/gpgpu18_scoped_persistent_barriers.pdf">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Arkaprava Basu, Sooraj Puthoor, and Mitesh Meswani
    <br/><span style="font-style:italic">11th Workshop on General Purpose Processing using GPU</span> (<b>GPGPU</b>), <span style="font-style:italic">In conjunction with Symp. on Principles and Practice of Parallel Programming</span> (PPoPP), Feb. 2018.
    </li>
    <br />
    
    <li>
    <font color="maroon">Apparatus and Method for Bias-Free Branch Prediction</font>
    <br/> Mikko Lipasti, and <span style="font-weight:bold"><u>Dibakar Gope</u></span>
    <br/>US Patent, 2018.
    </li>
    <br />
       
    <li>
    <font color="maroon">The CURE: Cluster Communication Using Registers</font> [<a href="http://pharm.ece.wisc.edu/papers/cases2017.pdf">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/>Vignyan Reddy Kothinti Naresh, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Mikko H. Lipasti
    <br/><span style="font-style:italic">Proceedings of the Int. Conf. on Compilers, Architecture, and Synthesis for Embedded Systems</span> (<b>CASES</b>), Oct. 2017.
    </li>
    <br />
    
    <li>
    <font color="maroon">Architectural Support for Server-Side PHP Processing</font> [<a href="http://pharm.ece.wisc.edu/papers/isca17_dgope.pdf">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, David J. Schlais, and Mikko H. Lipasti
    <br/><span style="font-style:italic">Proceedings of the 44th Int. Symp. on Computer Architecture</span> (<b>ISCA</b>), Jun. 2017.
    </li>
    <br />  
    
    <li>
    <font color="maroon">Hash Map Inlining</font> [<a href="http://pharm.ece.wisc.edu/papers/pact_hmi.pdf">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Mikko H. Lipasti
    <br/><span style="font-style:italic">Proceedings of the 25th Int. Conf. on Parallel Architectures and Compilation Techniques</span> (<b>PACT</b>), Sep. 2016.
    </li>
    <br />

    <li>
    <font color="maroon">Statement-Level Parallelism for Scripting Languages</font> [<a href="http://pharm.ece.wisc.edu/papers/slp_hpsl2015.pdf">Paper</a>] <!--[<a href="">Slides</a>]-->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Mikko H. Lipasti
    <br/><span style="font-style:italic">1st Workshop on the High Performance Scripting Languages</span>, <span style="font-style:italic">In conjunction with Symp. on Principles and Practice of Parallel Programming</span> (PPoPP), Feb. 2015.
    </li>
    <br />

    <li>
    <font color="maroon">Bias-Free Branch Predictor</font> [<a href="http://pharm.ece.wisc.edu/papers/micro14.pdf">Paper</a>] <!--[<a href="">Slides</a>] -->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Mikko H. Lipasti
    <br/><span style="font-style:italic">Proceedings of the 47th IEEE/ACM Int. Symp. on Microarchitecture</span> (<b>MICRO</b>), Dec. 2014.
    </li>
    <br />

    <li>
    <font color="maroon">Bias-Free Neural Predictor</font> [<a href="http://pharm.ece.wisc.edu/papers/cbp2014.pdf">Paper</a>] [<a href="https://www.jilp.org/cbp2014/code/DibakarGope.tar.gz">Code</a>]
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Mikko H. Lipasti
    <br/><span style="font-style:italic">Proceedings of the 4th JILP Workshop on Computer Architecture Competitions</span> (JWAC-4): <span style="font-style:italic">Championship Branch Prediction</span> (<b>CBP</b>), Jun. 2014.
    </li>
    <br />

    <li>
    <font color="maroon">Atomic SC for Simple In-order Processors</font> [<a href="http://pharm.ece.wisc.edu/papers/hpca14_gope.pdf">Paper</a>] <!--[<a href="">Slides</a>]-->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Mikko H. Lipasti
    <br/><span style="font-style:italic">Proceedings of the 20th IEEE Int. Symp. on High Performance Computer Architecture</span> (<b>HPCA</b>), Feb. 2014.
    <br/><font color="red">*Nominated for best paper award</font>
    </li>
    <br />

    <li>
    <font color="maroon">Maximizing Crosstalk-Induced Slowdown during Path Delay Test</font> [<a href="">Paper</a>] <!--[<a href="">Slides</a>]-->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, and Duncan M. (Hank) Walker
    <br/><span style="font-style:italic">Proceedings of the 30th IEEE Int. Conf. on Computer Design</span> (<b>ICCD</b>), Sep. 2012.
    </li>
    <br />

    <li>
    <font color="maroon">Exploring a Circuit Design Approach Based on One-Hot Multi-Valued Domino Logic</font> [<a href="">Paper</a>] <!--[<a href="">Slides</a>]-->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Kent Lin, and Sunil P. Khatri
    <br/><span style="font-style:italic">Proceedings of the 53rd IEEE Int. Midwest Symp. on Circuits & Systems</span> (<b>MWSCAS</b>), Aug. 2010.
    </li>
    <br />

    <li>
    <font color="maroon">Detection of High Resistance Bridge Defects using Slack Based Dynamic Bridging Fault Model</font> [<a href="">Paper</a>] <!--[<a href="">Slides</a>]-->
    <br/><span style="font-weight:bold"><u>Dibakar Gope</u></span>, Srinivasulu Alampally, Srinivas Kumar Vooka, and Rubin A. Parekhji
    <br/><span style="font-style:italic">Proceedings of the Synopsys Users Group India</span> (<b>SNUG</b>), 2008.
    </li>
    <br />
<!--</ol>

<hr noshade="noshade">
<h3>
    <b>Arxiv Preprints/Technical Report</b>
</h3>
<ol>-->
    <li>
    <font color="maroon">The gem5 Simulator: Version 20.0+</font> [<a href="https://arxiv.org/abs/2007.03152">ArXiv</a>] <!--[<a href="">Slides</a>] -->
    <br/>Jason Lowe-Power, Abdul Mutaal Ahmad, Ayaz Akram, Mohammad Alian, Rico Amslinger, Matteo Andreozzi, Adrià Armejach, Nils Asmussen, Srikant Bharadwaj, Gabe Black, Gedare Bloom, Bobby R. Bruce, Daniel Rodrigues Carvalho, Jeronimo Castrillon, Lizhong Chen, Nicolas Derumigny, Stephan Diestelhorst, Wendy Elsasser, Marjan Fariborz, Amin Farmahini-Farahani, Pouya Fotouhi, Ryan Gambord, Jayneel Gandhi, <span style="font-weight:bold"><u>Dibakar Gope</u></span>, Thomas Grass, Bagus Hanindhito, Andreas Hansson, Swapnil Haria, Austin Harris, Timothy Hayes, Adrian Herrera, Matthew Horsnell, Syed Ali Raza Jafri, Radhika Jagtap, Hanhwi Jang, Reiley Jeyapaul, Timothy M. Jones, Matthias Jung, Subash Kannoth, Hamidreza Khaleghzadeh, Yuetsu Kodama, Tushar Krishna, Tommaso Marinelli, Christian Menard, Andrea Mondelli, Tiago Mück, Omar Naji, Krishnendra Nathella, Hoa Nguyen, Nikos Nikoleris, Lena E. Olson, Marc Orr, Binh Pham, Pablo Prieto, Trivikram Reddy, Alec Roelke, Mahyar Samani, Andreas Sandberg, Javier Setoain, Boris Shingarov, Matthew D. Sinclair, Tuan Ta, Rahul Thakur, Giacomo Travaglini, Michael Upton, Nilay Vaish, Ilias Vougioukas, Zhengrong Wang, Norbert Wehn, Christian Weis, David A. Wood, Hongil Yoon, Éder F. Zulian.
    <br/>ArXiv, 2020.
    </li>
    <br /> 
</ol>

<hr noshade="noshade">
<h3>
    <b>Courses (Machine Learning)</b>
</h3>
<ul>
    Introduction to Deep Learning, Bayesian Methods for Machine Learning, Practical Reinforcement Learning, Natural Language Processing, Deep Learning in Computer Vision, Neural Networks and Deep Learning, <!--Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization-->, Convolutional Neural Networks, Sequence Models, Linear Algebra, Multivariate Calculus, Principal Component Analysis
    <!--</li></p>  
    <p><li>
    Introduction to Deep Learning (Advanced ML Specialization on Coursera)
    </li></p>
    <p><li>
    Bayesian Methods for Machine Learning (Advanced ML Specialization on Coursera)
    </li></p>
    <p><li>
    Practical Reinforcement Learning (Advanced ML Specialization on Coursera)
    </li></p>
    <p><li>
    Natural Language Processing (Advanced ML Specialization on Coursera)
    </li></p>
    <p><li>
    Deep Learning in Computer Vision (Advanced ML Specialization on Coursera)
    </li></p>
    <p><li>
    Neural Networks and Deep Learning (Deep Learning Specialization on Coursera)
    </li></p>
    <p><li>
    Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization (Deep Learning Specialization on Coursera)
    </li></p>
    <p><li>
    Structuring Machine Learning Projects (Deep Learning Specialization on Coursera)
    </li></p>
    <p><li>
    Convolutional Neural Networks (Deep Learning Specialization on Coursera)
    </li></p>
    <p><li>
    Sequence Models (Deep Learning Specialization on Coursera)
    </li></p>   
    <p><li>
    Linear Algebra (Mathematics for ML Specialization on Coursera)
    </li></p>
    <p><li>
    Multivariate Calculus (Mathematics for ML Specialization on Coursera)
    </li></p>
    <p><li>
    Principal Component Analysis (PCA) (Mathematics for ML Specialization on Coursera)    </li></p>
    <p><li>
    Introduction to Recommender Systems: Non-Personalized and Content-Based (Recommender Systems Specialization on Coursera)
    </li></p>
    <p><li>
    See my GitHub repositiry <a href="https://github.com/Dibakar/">GitHub</a> for the course certificates, and my Jupyter notebooks for various assignments and projects of these courses
    </li></p>--!>
</ul>

<!--<hr noshade="noshade">   
<h3>
    <b>Professional Services</b>
</h3>
<ul>
    <p><li>
    Program Committee Member
    <ul>
        <li> 
        Conference on Machine Learning and Systems (<a href="https://mlsys.org/Conferences/2022">MLSys</a>), 2022
        </li>
        <li>
        IEEE International Symposium on High-Performance Computer Architecture (<a href="https://hpca-conf.org/2023/">HPCA</a>) 2023
        </li>
        <li> 
        IEEE International Parallel & Distributed Processing Symposium (IPDPS), 2022
        </li> 
        <li>
        IEEE International Conference on Computer Design (<a href="http://www.iccd-conf.com/Home.html">ICCD</a>) 2021
        </li>        
        <li>
        IEEE International Conference on Parallel Architectures and Compilation Techniques (<a href="http://pact21.snu.ac.kr/">PACT</a>) 2021
        </li>
        <li>
        International Conference on Compilers, Architecture, and Synthesis of Embedded Systems (<a href="https://www.esweek.org/cases/about">CASES</a>) 2021
        </li>
        <li>
        ACM International Conference on Computing Frontiers (<a href="http://www.computingfrontiers.org/2021/">CF</a>) 2021
        </li>       
        <li>
        IEEE International Conference on Computer Design (<a href="http://www.iccd-conf.com/Home.html">ICCD</a>) 2020
        </li>       
        <li>
        ACM International Conference on Computing Frontiers (<a href="http://www.computingfrontiers.org/2020/">CF</a>) 2020
        </li>
        <li>
        IEEE International Conference on High Performance Computing, Data, and Analytics (<a href="https://hipc.org/">HiPC</a>) 2020
        </li>       
        <li>
        IEEE International Conference on Computer Design (<a href="http://www.iccd-conf.com/Home.html">ICCD</a>) 2019
        </li>
        <li>
        ACM International Conference on Computing Frontiers (<a href="http://computingfrontiers.org/2019/index.html">CF</a>) 2019
        </li>
        <li>
        International Conference on Compilers, Architecture, and Synthesis of Embedded Systems (<a href="https://www.esweek.org/cases/about">CASES</a>) 2019
        </li>
        <li>
        IEEE International Symposium on Workload Characterization (<a href="http://www.iiswc.org/iiswc2019/index.html">IISWC</a>) 2019
        </li>
        <li>
        Arm Research Summit (<a href="https://www.arm.com/company/events/research-summit">Arm Research Summit</a>) 2019
        </li>
    </ul>
    </li></p>   
    <p><li>   
    External Review Committee Member
    <ul>
        <li>
        ACM International Conference on Architectural Support for  Programming Languages and Operating Systems (<a href="https://asplos-conference.org/">ASPLOS</a>) 2023
        </li>
        <li>
        ACM/IEEE International Symposium on Computer Architecture (<a href="https://iscaconf.org/isca2022/">ISCA</a>) 2022
        </li>
        <li>
        ACM International Conference on Architectural Support for  Programming Languages and Operating Systems (<a href="https://asplos-conference.org/">ASPLOS</a>) 2022
        </li>
        <li>
        IEEE International Symposium on High-Performance Computer Architecture (<a href="https://hpca-conf.org/2022/">HPCA</a>) 2022
        </li>  
        <li>
        IEEE/ACM International Symposium on Microarchitecture (<a href="https://www.microarch.org/micro54/">MICRO</a>) 2021
        </li>              
        <li>
        ACM/IEEE International Symposium on Computer Architecture (<a href="https://iscaconf.org/isca2021/">ISCA</a>) 2021
        </li>
        <li>
        IEEE/ACM International Symposium on Microarchitecture (<a href="https://www.microarch.org/micro53/">MICRO</a>) 2020
        </li>       
        <li>
        IEEE International Symposium on Performance Analysis of Systems and Software (<a href="https://www.ispass.org/ispass2020//">ISPASS</a>) 2020
        </li>       
        <li>
        ACM/IEEE International Symposium on Computer Architecture (<a href="https://iscaconf.org/isca2020/">ISCA</a>) 2020
        </li>
        <li>
        ACM International Conference on Architectural Support for  Programming Languages and Operating Systems (<a href="https://asplos-conference.org/">ASPLOS</a>) 2020
        </li>
        <li>
        ACM/IEEE International Symposium on Computer Architecture (<a href="https://iscaconf.org/isca2019/">ISCA</a>) 2019
        </li>
        <li>
        IEEE International Conference on Parallel Architectures and Compilation Techniques (<a href="http://hpc.pnl.gov/pact19/">PACT</a>) 2019
        </li>
    </ul>   
    </li></p>
    <p><li>   
    Journals Review
    <ul>
        <li>
        ACM Transactions on Architecture and Code Optimization (<a href="">TACO</a>) 2020
        </li>       
        <li>
        IEEE Computer Architecture Letters (<a href="">CAL</a>) 2019
        </li>
        <li>
        IEEE Transactions on Computers (<a href="">TC</a>) 2019
        </li>
    </ul>   
    </li></p>   
</ul>-->

<hr noshade="noshade">
<h3>
    <b>Contact</b>
</h3>
<ul>
   <!--Email Address: "Last Name" [AT] wisc [DOT] edu<br> <br>--!>
   Linkedin: https://www.linkedin.com/in/dibakar-gope-89060119<br> <br>
</ul>

 </body>

</html>
